{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81f7a5c0",
      "metadata": {
        "id": "81f7a5c0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5b552c8",
      "metadata": {
        "id": "f5b552c8"
      },
      "outputs": [],
      "source": [
        "path = \"data_use_dirichlet/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6370222",
      "metadata": {
        "id": "e6370222"
      },
      "outputs": [],
      "source": [
        "if os.path.exists(path) == False:\n",
        "  os.mkdir(path)\n",
        "  raise Exception(f\"Upload data first at {path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1c7266f",
      "metadata": {
        "id": "d1c7266f"
      },
      "outputs": [],
      "source": [
        "# set wavenumber and wavelength\n",
        "k = 2.0 * np.pi\n",
        "lamb =  2.0 * np.pi / k\n",
        "\n",
        "# domain [la,lb]\n",
        "la = -12.0 * lamb\n",
        "lb = 12.0 * lamb\n",
        "\n",
        "# define the mesh for calculation\n",
        "N_obs = 240\n",
        "h_obs = (lb - la) / N_obs\n",
        "mesh_obs = np.linspace(la, lb, (N_obs + 1))\n",
        "\n",
        "mesh_mid_obs = np.zeros(N_obs + 1)\n",
        "\n",
        "mesh_mid_obs[0] = la\n",
        "\n",
        "for od in range(N_obs):\n",
        "    mesh_mid_obs[od + 1] = (mesh_obs[od] + mesh_obs[od+1])/2.0\n",
        "\n",
        "# transform numpy mesh to torch mesh\n",
        "x_mid_obs = torch.tensor(mesh_mid_obs, dtype = torch.float32, requires_grad = True)\n",
        "x_mesh_obs = torch.tensor(mesh_obs, dtype = torch.float32, requires_grad = True)\n",
        "\n",
        "# mesh point input for the trunk network\n",
        "x_tensor = x_mid_obs[1:]\n",
        "x_tensors = x_tensor.detach()\n",
        "\n",
        "# surface height range\n",
        "hmax = 0.2 * lamb\n",
        "hmin = -0.2 * lamb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "217ece43",
      "metadata": {
        "id": "217ece43"
      },
      "outputs": [],
      "source": [
        "# load data\n",
        "data1 = torch.load(path+'data1.pt')\n",
        "data2 = torch.load(path+'data2.pt')\n",
        "data3 = torch.load(path+'data3.pt')\n",
        "data4 = torch.load(path+'data4.pt')\n",
        "data5 = torch.load(path+'data5.pt')\n",
        "data6 = torch.load(path+'data6.pt')\n",
        "data7 = torch.load(path+'data7.pt')\n",
        "data8 = torch.load(path+'data8.pt')\n",
        "data9 = torch.load(path+'data9.pt')\n",
        "data10 = torch.load(path+'data10.pt')\n",
        "data11 = torch.load(path+'data11.pt')\n",
        "data12 = torch.load(path+'data12.pt')\n",
        "data13 = torch.load(path+'data13.pt')\n",
        "data14 = torch.load(path+'data14.pt')\n",
        "data15 = torch.load(path+'data15.pt')\n",
        "data16 = torch.load(path+'data16.pt')\n",
        "data17 = torch.load(path+'data17.pt')\n",
        "data18 = torch.load(path+'data18.pt')\n",
        "data19 = torch.load(path+'data19.pt')\n",
        "data20 = torch.load(path+'data20.pt')\n",
        "\n",
        "data_train = data1 + data2 + data3 + data4 + data5 + data6 + data7 + data8 + data9 + data10 \\\n",
        "+ data11 + data12 + data13 +data14 + data15 + data16 + data17 + data18 + data19 + data20\n",
        "\n",
        "size_data = len(data_train)\n",
        "print('total number of data = ', size_data)\n",
        "\n",
        "# put surface height, scattered data, and measurement height in arrays\n",
        "hei_array = []\n",
        "phis_array = []\n",
        "zz_array = []\n",
        "\n",
        "for i in range(size_data):\n",
        "    hei_array.append(data_train[i][0])\n",
        "    phis_array.append(data_train[i][1])\n",
        "    zz_array.append(data_train[i][2])\n",
        "\n",
        "# stack the data in one tensor\n",
        "hei_tensors = torch.stack(hei_array).detach()\n",
        "phis_tensors = torch.stack(phis_array).detach()\n",
        "phis_real_tensors = torch.real(phis_tensors)\n",
        "phis_imag_tensors = torch.imag(phis_tensors)\n",
        "zz_tensors = torch.stack(zz_array).detach()\n",
        "\n",
        "\n",
        "# note that the normalzation range is [-0.5,0.5]\n",
        "def normalize_tensor(input_tensor):\n",
        "\n",
        "    min_val = torch.min(input_tensor)\n",
        "    max_val = torch.max(input_tensor)\n",
        "    normalized_tensor = (input_tensor - min_val) / (max_val - min_val) - 0.5\n",
        "\n",
        "    return normalized_tensor\n",
        "\n",
        "# normalization of data\n",
        "normalized_hei_tensors = normalize_tensor(hei_tensors)\n",
        "normalized_phis_real_tensors = normalize_tensor(phis_real_tensors)\n",
        "normalized_phis_imag_tensors = normalize_tensor(phis_imag_tensors)\n",
        "normalized_x_tensors = normalize_tensor(x_tensors)\n",
        "normalized_zz_tensors = normalize_tensor(zz_tensors)\n",
        "\n",
        "\n",
        "# inverse normalization of data, used for plotting original surface height\n",
        "def inverse_normalize_tensor(normalized_tensor, original_max, original_min):\n",
        "\n",
        "    return (normalized_tensor + 0.5) * (original_max - original_min) + original_min"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04840b95",
      "metadata": {
        "id": "04840b95"
      },
      "source": [
        "structure for a uniform feed-forward neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5d57ddc",
      "metadata": {
        "lines_to_next_cell": 1,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "b5d57ddc",
        "outputId": "6e325c1a-b149-4faa-8612-7f6e9f5519e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Reference CNN implementation for branch2.\\n# Minimises loss upto 9e-4 with 15000 epochs.\\n# Alternatively, reaches loss to the order of 6e-3 in 2400 epochs.\\n# However, DeepONet has 134154 learnable parameters (Almost double that of FNN).\\n# Serves as good benchmark for finetuning CNN architecture.\\nclass CNN(nn.Module):\\n    def __init__(self):\\n        super().__init__()\\n        self.activation = torch.nn.Tanh()\\n        self.conv1 = torch.nn.Sequential(\\n            torch.nn.Conv1d(\\n                in_channels = 1,\\n                out_channels = 4,\\n                kernel_size = 11, # 7,\\n                stride = 1,\\n                padding = 2,\\n            ),\\n            torch.nn.BatchNorm1d(4),\\n            torch.nn.Tanh(), # torch.nn.ReLU(),\\n            torch.nn.MaxPool1d(3),\\n        )\\n\\n        self.conv2 = torch.nn.Sequential(\\n            torch.nn.Conv1d(\\n                in_channels = 4,\\n                out_channels = 8,\\n                kernel_size = 5,\\n                stride = 1,\\n                padding = 2,\\n            ),\\n            torch.nn.BatchNorm1d(8),\\n            torch.nn.Tanh(), # torch.nn.ReLU(),\\n            torch.nn.MaxPool1d(3),\\n        )\\n\\n        self.fnn1 = torch.nn.Linear(416, 234)\\n        self.fnn2 = torch.nn.Linear(234, 64)\\n\\n    def forward(self, x):\\n        assert torch.isinf(x).any() != True\\n        x = self.conv1(x)\\n        assert torch.isinf(x).any() != True\\n        x = self.conv2(x)\\n        assert torch.isinf(x).any() != True\\n        x = x.view(x.size(0), -1)\\n        output = self.activation(self.fnn1(x))\\n        output = self.activation(self.fnn2(output))\\n        return output\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "class FNN(nn.Module):\n",
        "\n",
        "    # input_size: the size of input tensor\n",
        "    # output_size: size of output tensor\n",
        "    # hidden_layers: number of hidden layers\n",
        "    # hidden_neurons: number of hidden neurons per hidden layer\n",
        "    # activation: activation function\n",
        "\n",
        "    def __init__(self, input_size, output_size, hidden_layers, hidden_neurons, activation):\n",
        "\n",
        "        super(FNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "        self.hidden_layers = hidden_layers\n",
        "        self.hidden_neurons = hidden_neurons\n",
        "        self.activation = activation\n",
        "\n",
        "        self.input_layer = nn.Linear(input_size, hidden_neurons)\n",
        "        self.hidden_layers_list = nn.ModuleList()\n",
        "        for _ in range(hidden_layers - 1):\n",
        "            self.hidden_layers_list.append(nn.Linear(hidden_neurons, hidden_neurons))\n",
        "        self.output_layer = nn.Linear(hidden_neurons, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.activation(self.input_layer(x))\n",
        "\n",
        "        for hidden_layer in self.hidden_layers_list:\n",
        "            x = self.activation(hidden_layer(x))\n",
        "\n",
        "        x = self.activation(self.output_layer(x))\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82cc0d8a",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "82cc0d8a"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.activation = torch.nn.Tanh()\n",
        "        self.conv1 = torch.nn.Sequential(\n",
        "            torch.nn.Conv1d(\n",
        "                in_channels = 2,\n",
        "                out_channels = 4,\n",
        "                kernel_size = 11,\n",
        "                stride = 1,\n",
        "                padding = 2,\n",
        "            ),\n",
        "            torch.nn.BatchNorm1d(4),\n",
        "            torch.nn.Tanh(), # torch.nn.ReLU(),\n",
        "            torch.nn.AvgPool1d(3), # torch.nn.MaxPool1d(3),\n",
        "        )\n",
        "\n",
        "        self.conv2 = torch.nn.Sequential(\n",
        "            torch.nn.Conv1d(\n",
        "                in_channels = 4,\n",
        "                out_channels = 6,\n",
        "                kernel_size = 7,\n",
        "                stride = 1,\n",
        "                padding = 2,\n",
        "            ),\n",
        "            torch.nn.BatchNorm1d(6),\n",
        "            torch.nn.Tanh(), # torch.nn.ReLU(),\n",
        "            torch.nn.AvgPool1d(3), # torch.nn.MaxPool1d(3),\n",
        "        )\n",
        "\n",
        "        self.fnn1 = torch.nn.Linear(150, 64)\n",
        "        self.fnn2 = torch.nn.Linear(64, 64)\n",
        "        self.fnn3 = torch.nn.Linear(64, 64)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        output = self.activation(self.fnn1(x))\n",
        "        output = self.activation(self.fnn2(output))\n",
        "        output = self.activation(self.fnn3(output))\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d0ec3a5",
      "metadata": {
        "id": "5d0ec3a5"
      },
      "source": [
        "main structure of DeepONet with multiple inputs (two inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8965c2fd",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "8965c2fd"
      },
      "outputs": [],
      "source": [
        "class DeepONet(nn.Module):\n",
        "\n",
        "    # this deeponet contains 2 branch nets and 1 trunk net\n",
        "    # input_size_branch1: size of input tensor for branch net1\n",
        "    # hidden_layers_branch1: number of hidden layers in branch net1\n",
        "    # hidden_neurons_branch1: number of neurons per hidden layer in branch net1\n",
        "    # input_size_branch2: size of input tensor for branch net2\n",
        "    # hidden_layers_branch2: number of hidden layers in branch net2\n",
        "    # hidden_neurons_branch2: number of neurons per hidden layer in branch net2\n",
        "    # hidden_layers_trunk: number of hidden layers in trunk net\n",
        "    # hidden_neurons_trunk: number of neurons per hidden layer in trunk net\n",
        "    # inner_layer_siz: size of the inner layer, i.e. value of p\n",
        "    # activation: activation function\n",
        "    # size_bias: size of the output bias tensor\n",
        "\n",
        "    def __init__(self, input_size_branch1, hidden_layers_branch1, hidden_neurons_branch1, \\\n",
        "                 input_size_branch2, hidden_layers_branch2, hidden_neurons_branch2, \\\n",
        "                 hidden_layers_trunk, hidden_neurons_trunk, \\\n",
        "                 inner_layer_size, activation, size_bias):\n",
        "\n",
        "        super(DeepONet, self).__init__()\n",
        "        self.branch1 = FNN(input_size_branch1, inner_layer_size, hidden_layers_branch1, \\\n",
        "                           hidden_neurons_branch1, activation)\n",
        "        self.branch2 = CNN() # FNN(input_size_branch2, inner_layer_size, hidden_layers_branch2, \\\n",
        "                           # hidden_neurons_branch2, activation)\n",
        "        self.trunk = FNN(1, inner_layer_size, hidden_layers_trunk, hidden_neurons_trunk, activation)\n",
        "\n",
        "        self.bias = nn.Parameter(torch.Tensor(1, size_bias))\n",
        "\n",
        "    def forward(self, input_tensor_branch1, input_tensor_branch2, input_tensor_trunk):\n",
        "\n",
        "        # input tensor for branch net1 is input_tensor_branch1\n",
        "        # input tensor for branch net2 is input_tensor_branch2\n",
        "        # input tensor for trunk net is input_tensor_trunk\n",
        "\n",
        "        b_tensor = self.branch1(input_tensor_branch1)\n",
        "        s_tensor = self.branch2(input_tensor_branch2)\n",
        "        b = b_tensor * s_tensor\n",
        "\n",
        "        input_tensor_trunk = input_tensor_trunk.view(-1, 1)\n",
        "        t = self.trunk(input_tensor_trunk)\n",
        "\n",
        "        output =  torch.matmul(b, t.T) + self.bias.squeeze()\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set up deeponet\n",
        "\n",
        "# input of the branch net 1 is the measurement height Z\n",
        "input_size_branch1 = 1\n",
        "hidden_layers_branch1 = 3\n",
        "hidden_neurons_branch1 = 32\n",
        "\n",
        "# input of the branch net 2 is the real and imaginary parts of scattered data\n",
        "input_size_branch2 = N_obs * 2\n",
        "hidden_layers_branch2 = 4\n",
        "hidden_neurons_branch2 = 64\n",
        "\n",
        "# input of the trunk net\n",
        "hidden_layers_trunk = 4\n",
        "hidden_neurons_trunk = 64\n",
        "\n",
        "# input layer size, value of p\n",
        "inner_layer_size = 64\n",
        "\n",
        "# activation function\n",
        "activation = nn.Tanh()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('calculation device : ', device)\n",
        "\n",
        "\n",
        "model = DeepONet(input_size_branch1, hidden_layers_branch1, hidden_neurons_branch1, \\\n",
        "                 input_size_branch2, hidden_layers_branch2, hidden_neurons_branch2, \\\n",
        "                 hidden_layers_trunk, hidden_neurons_trunk, \\\n",
        "                 inner_layer_size, activation, N_obs).to(device)\n",
        "\n",
        "# count the number of hyperparameters in the neural network\n",
        "def number_parameter_count(network):\n",
        "\n",
        "    num_trainable_para = 0\n",
        "    for param in network.parameters():\n",
        "        if param.requires_grad == True:\n",
        "            num_trainable_para += np.product(param.shape)\n",
        "\n",
        "    return num_trainable_para\n",
        "\n",
        "num_trainable_para = number_parameter_count(model)\n",
        "print(f\"Number of learnable model parameters: {num_trainable_para}\")"
      ],
      "metadata": {
        "id": "8Mj6Mw_yyRoh"
      },
      "id": "8Mj6Mw_yyRoh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73bb204e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73bb204e",
        "outputId": "3080a123-cefd-49be-843f-12744747d986"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time cost: 17.71 minutes\n"
          ]
        }
      ],
      "source": [
        "# set the number of training data and testing data\n",
        "size_training_data = 15000\n",
        "size_testing_data = 5000\n",
        "\n",
        "# set batch size\n",
        "size_batch = 3000\n",
        "\n",
        "# choose optimizer and learning rate\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# number of epochs\n",
        "num_epochs = 15000\n",
        "\n",
        "time1 = time.time()\n",
        "\n",
        "# main loop for the deeponet\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    total_loss = 0\n",
        "\n",
        "    # loof for batches\n",
        "    for i in range(0, size_training_data, size_batch):\n",
        "\n",
        "        # data for the output\n",
        "        hei_data_tensor = normalized_hei_tensors[i:i + size_batch].to(device)\n",
        "\n",
        "        # branch net1 input: measurement height Z\n",
        "        zz_input_tensor = normalized_zz_tensors[i:i + size_batch].to(device)\n",
        "\n",
        "        # branch net2 input: real and imaginary parts of scattered data\n",
        "        sc_real_tensor = normalized_phis_real_tensors[i:i + size_batch].to(device)\n",
        "        sc_imag_tensor = normalized_phis_imag_tensors[i:i + size_batch].to(device)\n",
        "        # sc_input_tensor = (torch.cat((sc_real_tensor, sc_imag_tensor), dim=1)).unsqueeze(1)\n",
        "        sc_input_tensor = torch.stack((sc_real_tensor, sc_imag_tensor), dim=1)\n",
        "\n",
        "        # deeponet output\n",
        "        hei_pred_tensor = model(zz_input_tensor, sc_input_tensor, normalized_x_tensors.to(device))\n",
        "\n",
        "        # loss function\n",
        "        loss = nn.MSELoss()(hei_pred_tensor, hei_data_tensor)\n",
        "\n",
        "        # optimizing step with backward propagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward(retain_graph=True)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        print(f'Epoch [{epoch+1}], Loss: {total_loss:.10f}')\n",
        "\n",
        "\n",
        "time2 = time.time()\n",
        "time_cost_minutes = (time2 - time1) / 60\n",
        "print(f\"Training time cost: {time_cost_minutes:.2f} minutes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ab5a29e",
      "metadata": {
        "id": "7ab5a29e"
      },
      "outputs": [],
      "source": [
        "# test results using testing data\n",
        "\n",
        "ntest = 19720\n",
        "\n",
        "# original surface height\n",
        "hei_actual_tensor = normalized_hei_tensors[ntest]\n",
        "hei_actual = inverse_normalize_tensor(hei_actual_tensor, hmax, hmin)\n",
        "hei_actual_vec = hei_actual.cpu().detach().numpy()\n",
        "\n",
        "# input datas\n",
        "zz_tensor_test = normalized_zz_tensors[ntest].to(device)\n",
        "sc_real_tensor_test = normalized_phis_real_tensors[ntest].to(device)\n",
        "sc_imag_tensor_test = normalized_phis_imag_tensors[ntest].to(device)\n",
        "sc_input_tensor_test = torch.stack((sc_real_tensor_test, sc_imag_tensor_test), dim=1).unsqueeze(0)\n",
        "sc_input_tensor_test = sc_input_tensor_test.transpose(1, 2)\n",
        "\n",
        "\n",
        "# output data (predicted surface)\n",
        "hei_pred_tensor_test = model(zz_tensor_test, sc_input_tensor_test, normalized_x_tensors.to(device))\n",
        "hei_pred = inverse_normalize_tensor(hei_pred_tensor_test, hmax, hmin)\n",
        "hei_pred_vec = hei_pred.cpu().detach().numpy().squeeze(0)\n",
        "\n",
        "line1, = plt.plot(mesh_mid_obs[1:] / lamb, hei_actual_vec / lamb)\n",
        "line2, = plt.plot(mesh_mid_obs[1:] / lamb, hei_pred_vec / lamb)\n",
        "plt.xlabel(r'$x/{\\lambda}$')\n",
        "plt.ylabel(r'$z/{\\lambda}$')\n",
        "leg=plt.legend([line1, line2],\n",
        "        ['actual surface',\n",
        "        'reconstructed surface'], loc = \"best\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3805a1a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3805a1a",
        "outputId": "8c317c8d-d0bd-4a94-93f6-b24014d2ef90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "l2 norm error is:  0.19839406\n"
          ]
        }
      ],
      "source": [
        "# calculate the l2 norm error\n",
        "error_vec = hei_actual_vec - hei_pred_vec\n",
        "print(\"l2 norm error is: \", np.linalg.norm(error_vec) / np.linalg.norm(hei_actual_vec))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "088298e2",
      "metadata": {
        "id": "088298e2"
      },
      "outputs": [],
      "source": [
        "# save the hyperparameters\n",
        "torch.save(model.state_dict(), 'model_cnn_parameters_dirichlet.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26e983e7",
      "metadata": {
        "id": "26e983e7"
      },
      "outputs": [],
      "source": [
        "def test_error(ntest):\n",
        "\n",
        "    # original surface height\n",
        "    hei_actual_tensor = normalized_hei_tensors[ntest]\n",
        "    hei_actual = inverse_normalize_tensor(hei_actual_tensor, hmax, hmin)\n",
        "    hei_actual_vec = hei_actual.cpu().detach().numpy()\n",
        "\n",
        "    # input datas\n",
        "    zz_tensor_test = normalized_zz_tensors[ntest].to(device)\n",
        "    sc_real_tensor_test = normalized_phis_real_tensors[ntest].to(device)\n",
        "    sc_imag_tensor_test = normalized_phis_imag_tensors[ntest].to(device)\n",
        "    sc_input_tensor_test = torch.stack((sc_real_tensor_test, sc_imag_tensor_test), dim=1).unsqueeze(0)\n",
        "    sc_input_tensor_test = sc_input_tensor_test.transpose(1, 2)\n",
        "\n",
        "    # output data (predicted surface)\n",
        "    hei_pred_tensor_test = model(zz_tensor_test, sc_input_tensor_test, normalized_x_tensors.to(device))\n",
        "    hei_pred = inverse_normalize_tensor(hei_pred_tensor_test, hmax, hmin)\n",
        "    hei_pred_vec = hei_pred.cpu().detach().numpy().squeeze(0)\n",
        "\n",
        "    # calculate the l2 norm error\n",
        "    error_vec = hei_actual_vec - hei_pred_vec\n",
        "\n",
        "    l2_error = np.linalg.norm(error_vec) / np.linalg.norm(hei_actual_vec)\n",
        "\n",
        "    return l2_error\n",
        "\n",
        "l2_errors_test = np.array([test_error(n) for n in range(15000, 20000)])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "average_l2_error = np.mean(l2_errors_test)\n",
        "print('average l2 norm error for test data set is ', average_l2_error)\n",
        "\n",
        "std_dev_l2_error = np.std(l2_errors_test)\n",
        "print('standard deviation of l2 norm error for test data set is ', std_dev_l2_error)"
      ],
      "metadata": {
        "id": "3DIBdCRWzLzM"
      },
      "id": "3DIBdCRWzLzM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test the method with noisy data\n",
        "\n",
        "ntest = 19720\n",
        "\n",
        "# original surface height\n",
        "hei_actual_tensor = normalized_hei_tensors[ntest]\n",
        "hei_actual = inverse_normalize_tensor(hei_actual_tensor, hmax, hmin)\n",
        "hei_actual_vec = hei_actual.cpu().detach().numpy()\n",
        "\n",
        "# input datas\n",
        "zz_tensor_test = normalized_zz_tensors[ntest].to(device)\n",
        "sc_real_tensor_test = normalized_phis_real_tensors[ntest].to(device)\n",
        "sc_imag_tensor_test = normalized_phis_imag_tensors[ntest].to(device)\n",
        "\n",
        "# add white noise to the scattered data\n",
        "# noise level eps\n",
        "eps = 0.1\n",
        "# random numbers in [-1,1]\n",
        "random_float = (torch.rand_like(sc_real_tensor_test) - 0.5) * 2\n",
        "sc_real_tensor_noise = sc_real_tensor_test * (1 + eps * random_float)\n",
        "sc_imag_tensor_noise = sc_imag_tensor_test * (1 + eps * random_float)\n",
        "sc_input_tensor_noise = torch.stack((sc_real_tensor_noise, sc_imag_tensor_noise), dim=1).unsqueeze(0)\n",
        "sc_input_tensor_noise = sc_input_tensor_noise.transpose(1, 2)\n",
        "\n",
        "# output data (predicted surface)\n",
        "hei_pred_tensor_noise = model(zz_tensor_test, sc_input_tensor_noise, normalized_x_tensors.to(device))\n",
        "hei_pred_noise = inverse_normalize_tensor(hei_pred_tensor_noise, hmax, hmin)\n",
        "hei_pred_vec = hei_pred_noise.cpu().detach().numpy().squeeze(0)\n",
        "\n",
        "line1, = plt.plot(mesh_mid_obs[1:] / lamb, hei_actual_vec / lamb)\n",
        "line2, = plt.plot(mesh_mid_obs[1:] / lamb, hei_pred_vec / lamb)\n",
        "plt.xlabel(r'$x/{\\lambda}$')\n",
        "plt.ylabel(r'$z/{\\lambda}$')\n",
        "leg=plt.legend([line1, line2],\n",
        "        ['actual surface',\n",
        "        'reconstructed surface'], loc = \"best\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ruLWRtl_zPXR"
      },
      "id": "ruLWRtl_zPXR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the l2 norm error\n",
        "error_vec = hei_actual_vec - hei_pred_vec\n",
        "print(\"l2 norm error is: \", np.linalg.norm(error_vec) / np.linalg.norm(hei_actual_vec))"
      ],
      "metadata": {
        "id": "AdGziwmfzTo1"
      },
      "id": "AdGziwmfzTo1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_error_with_noise(ntest):\n",
        "\n",
        "    # original surface height\n",
        "    hei_actual_tensor = normalized_hei_tensors[ntest]\n",
        "    hei_actual = inverse_normalize_tensor(hei_actual_tensor, hmax, hmin)\n",
        "    hei_actual_vec = hei_actual.cpu().detach().numpy()\n",
        "\n",
        "    # input datas\n",
        "    zz_tensor_test = normalized_zz_tensors[ntest].to(device)\n",
        "    sc_real_tensor_test = normalized_phis_real_tensors[ntest].to(device)\n",
        "    sc_imag_tensor_test = normalized_phis_imag_tensors[ntest].to(device)\n",
        "\n",
        "    # add white noise to the scattered data\n",
        "    # noise level eps\n",
        "    eps = 0.08\n",
        "    # random numbers in [-1,1]\n",
        "    random_float = (torch.rand_like(sc_real_tensor_test) - 0.5) * 2\n",
        "    sc_real_tensor_noise = sc_real_tensor_test * (1 + eps * random_float)\n",
        "    sc_imag_tensor_noise = sc_imag_tensor_test * (1 + eps * random_float)\n",
        "    sc_input_tensor_noise = torch.stack((sc_real_tensor_noise, sc_imag_tensor_noise), dim=1).unsqueeze(0)\n",
        "    sc_input_tensor_noise = sc_input_tensor_noise.transpose(1, 2)\n",
        "\n",
        "    # output data (predicted surface)\n",
        "    hei_pred_tensor_noise = model(zz_tensor_test, sc_input_tensor_noise, normalized_x_tensors.to(device))\n",
        "    hei_pred_noise = inverse_normalize_tensor(hei_pred_tensor_noise, hmax, hmin)\n",
        "    hei_pred_vec = hei_pred_noise.cpu().detach().numpy().squeeze(0)\n",
        "\n",
        "    # calculate the l2 norm error\n",
        "    error_vec = hei_actual_vec - hei_pred_vec\n",
        "\n",
        "    l2_error = np.linalg.norm(error_vec) / np.linalg.norm(hei_actual_vec)\n",
        "\n",
        "    return l2_error\n",
        "\n",
        "l2_errors_noise_test = np.array([test_error_with_noise(n) for n in range(15000, 20000)])"
      ],
      "metadata": {
        "id": "NpH7EPgTzXDx"
      },
      "id": "NpH7EPgTzXDx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "average_l2_error_noise = np.mean(l2_errors_noise_test)\n",
        "print('average l2 norm error for noisy test data set is ', average_l2_error_noise)\n",
        "\n",
        "std_dev_l2_error_noise = np.std(l2_errors_noise_test)\n",
        "print('standard deviation of l2 norm error for noisy test data set is ', std_dev_l2_error_noise)"
      ],
      "metadata": {
        "id": "37-jNQC6zaFW"
      },
      "id": "37-jNQC6zaFW",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "encoding": "# -*- coding: utf-8 -*-",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}