{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e255c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"deeponet_surface_dirichlet_cnn_branch_2.ipynb\n",
    "\n",
    "Automatically generated by Colab.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1oPKOdtSckZAq2_NlfASiHbq8N_aL0H9g\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f7a5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b552c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data_use_dirichlet/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6370222",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(path) == False:\n",
    "  os.mkdir(path)\n",
    "  raise Exception(f\"Upload data first at {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c7266f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set wavenumber and wavelength\n",
    "k = 2.0 * np.pi\n",
    "lamb =  2.0 * np.pi / k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c367b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# domain [la,lb]\n",
    "la = -12.0 * lamb\n",
    "lb = 12.0 * lamb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd544e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the mesh for calculation\n",
    "N_obs = 240\n",
    "h_obs = (lb - la) / N_obs\n",
    "mesh_obs = np.linspace(la, lb, (N_obs + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8c98a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_mid_obs = np.zeros(N_obs + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1f8760",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_mid_obs[0] = la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0200e8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for od in range(N_obs):\n",
    "    mesh_mid_obs[od + 1] = (mesh_obs[od] + mesh_obs[od+1])/2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e80657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform numpy mesh to torch mesh\n",
    "x_mid_obs = torch.tensor(mesh_mid_obs, dtype = torch.float32, requires_grad = True)\n",
    "x_mesh_obs = torch.tensor(mesh_obs, dtype = torch.float32, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5580778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mesh point input for the trunk network\n",
    "x_tensor = x_mid_obs[1:]\n",
    "x_tensors = x_tensor.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5032fdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# surface height range\n",
    "hmax = 0.2 * lamb\n",
    "hmin = -0.2 * lamb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217ece43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data1 = torch.load(path+'data1.pt')\n",
    "data2 = torch.load(path+'data2.pt')\n",
    "data3 = torch.load(path+'data3.pt')\n",
    "data4 = torch.load(path+'data4.pt')\n",
    "data5 = torch.load(path+'data5.pt')\n",
    "data6 = torch.load(path+'data6.pt')\n",
    "data7 = torch.load(path+'data7.pt')\n",
    "data8 = torch.load(path+'data8.pt')\n",
    "data9 = torch.load(path+'data9.pt')\n",
    "data10 = torch.load(path+'data10.pt')\n",
    "data11 = torch.load(path+'data11.pt')\n",
    "data12 = torch.load(path+'data12.pt')\n",
    "data13 = torch.load(path+'data13.pt')\n",
    "data14 = torch.load(path+'data14.pt')\n",
    "data15 = torch.load(path+'data15.pt')\n",
    "data16 = torch.load(path+'data16.pt')\n",
    "data17 = torch.load(path+'data17.pt')\n",
    "data18 = torch.load(path+'data18.pt')\n",
    "data19 = torch.load(path+'data19.pt')\n",
    "data20 = torch.load(path+'data20.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6866cd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data1 + data2 + data3 + data4 + data5 + data6 + data7 + data8 + data9 + data10 \\\n",
    "+ data11 + data12 + data13 +data14 + data15 + data16 + data17 + data18 + data19 + data20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bea43e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_data = len(data_train)\n",
    "print('total number of data = ', size_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6662f114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put surface height, scattered data, and measurement height in arrays\n",
    "hei_array = []\n",
    "phis_array = []\n",
    "zz_array = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd71a1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(size_data):\n",
    "    hei_array.append(data_train[i][0])\n",
    "    phis_array.append(data_train[i][1])\n",
    "    zz_array.append(data_train[i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9574a38",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# stack the data in one tensor\n",
    "hei_tensors = torch.stack(hei_array).detach()\n",
    "phis_tensors = torch.stack(phis_array).detach()\n",
    "phis_real_tensors = torch.real(phis_tensors)\n",
    "phis_imag_tensors = torch.imag(phis_tensors)\n",
    "zz_tensors = torch.stack(zz_array).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fbd4ce",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# note that the normalzation range is [-0.5,0.5]\n",
    "def normalize_tensor(input_tensor):\n",
    "\n",
    "    min_val = torch.min(input_tensor)\n",
    "    max_val = torch.max(input_tensor)\n",
    "    normalized_tensor = (input_tensor - min_val) / (max_val - min_val) - 0.5\n",
    "\n",
    "    return normalized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d28b18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization of data\n",
    "normalized_hei_tensors = normalize_tensor(hei_tensors)\n",
    "normalized_phis_real_tensors = normalize_tensor(phis_real_tensors)\n",
    "normalized_phis_imag_tensors = normalize_tensor(phis_imag_tensors)\n",
    "normalized_x_tensors = normalize_tensor(x_tensors)\n",
    "normalized_zz_tensors = normalize_tensor(zz_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3586f75",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# inverse normalization of data, used for plotting original surface height\n",
    "def inverse_normalize_tensor(normalized_tensor, original_max, original_min):\n",
    "\n",
    "    return (normalized_tensor + 0.5) * (original_max - original_min) + original_min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04840b95",
   "metadata": {},
   "source": [
    "structure for a uniform feed-forward neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d57ddc",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class FNN(nn.Module):\n",
    "\n",
    "    # input_size: the size of input tensor\n",
    "    # output_size: size of output tensor\n",
    "    # hidden_layers: number of hidden layers\n",
    "    # hidden_neurons: number of hidden neurons per hidden layer\n",
    "    # activation: activation function\n",
    "\n",
    "    def __init__(self, input_size, output_size, hidden_layers, hidden_neurons, activation):\n",
    "\n",
    "        super(FNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.hidden_neurons = hidden_neurons\n",
    "        self.activation = activation\n",
    "\n",
    "        self.input_layer = nn.Linear(input_size, hidden_neurons)\n",
    "        self.hidden_layers_list = nn.ModuleList()\n",
    "        for _ in range(hidden_layers - 1):\n",
    "            self.hidden_layers_list.append(nn.Linear(hidden_neurons, hidden_neurons))\n",
    "        self.output_layer = nn.Linear(hidden_neurons, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.activation(self.input_layer(x))\n",
    "\n",
    "        for hidden_layer in self.hidden_layers_list:\n",
    "            x = self.activation(hidden_layer(x))\n",
    "\n",
    "        x = self.activation(self.output_layer(x))\n",
    "\n",
    "        return x\n",
    "'''\n",
    "# Reference CNN implementation for branch2.\n",
    "# Minimises loss upto 9e-4 with 15000 epochs.\n",
    "# Alternatively, reaches loss to the order of 6e-3 in 2400 epochs.\n",
    "# However, DeepONet has 134154 learnable parameters (Almost double that of FNN).\n",
    "# Serves as good benchmark for finetuning CNN architecture.\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.activation = torch.nn.Tanh()\n",
    "        self.conv1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(\n",
    "                in_channels = 1,\n",
    "                out_channels = 4,\n",
    "                kernel_size = 11, # 7,\n",
    "                stride = 1,\n",
    "                padding = 2,\n",
    "            ),\n",
    "            torch.nn.BatchNorm1d(4),\n",
    "            torch.nn.Tanh(), # torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool1d(3),\n",
    "        )\n",
    "\n",
    "        self.conv2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(\n",
    "                in_channels = 4,\n",
    "                out_channels = 8,\n",
    "                kernel_size = 5,\n",
    "                stride = 1,\n",
    "                padding = 2,\n",
    "            ),\n",
    "            torch.nn.BatchNorm1d(8),\n",
    "            torch.nn.Tanh(), # torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool1d(3),\n",
    "        )\n",
    "\n",
    "        self.fnn1 = torch.nn.Linear(416, 234)\n",
    "        self.fnn2 = torch.nn.Linear(234, 64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert torch.isinf(x).any() != True\n",
    "        x = self.conv1(x)\n",
    "        assert torch.isinf(x).any() != True\n",
    "        x = self.conv2(x)\n",
    "        assert torch.isinf(x).any() != True\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.activation(self.fnn1(x))\n",
    "        output = self.activation(self.fnn2(output))\n",
    "        return output\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cc0d8a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.activation = torch.nn.Tanh()\n",
    "        self.conv1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(\n",
    "                in_channels = 1,\n",
    "                out_channels = 4,\n",
    "                kernel_size = 11, # 7,\n",
    "                stride = 1,\n",
    "                padding = 2,\n",
    "            ),\n",
    "            torch.nn.BatchNorm1d(4),\n",
    "            torch.nn.Tanh(), # torch.nn.ReLU(),\n",
    "            torch.nn.AvgPool1d(3), # torch.nn.MaxPool1d(3),\n",
    "        )\n",
    "\n",
    "        self.conv2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(\n",
    "                in_channels = 4,\n",
    "                out_channels = 8,\n",
    "                kernel_size = 5,\n",
    "                stride = 1,\n",
    "                padding = 2,\n",
    "            ),\n",
    "            torch.nn.BatchNorm1d(8),\n",
    "            torch.nn.Tanh(), # torch.nn.ReLU(),\n",
    "            torch.nn.AvgPool1d(3), # torch.nn.MaxPool1d(3),\n",
    "        )\n",
    "\n",
    "        self.conv3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(\n",
    "                in_channels = 8,\n",
    "                out_channels = 8,\n",
    "                kernel_size = 5,\n",
    "                stride = 1,\n",
    "                padding = 2,\n",
    "            ),\n",
    "            torch.nn.BatchNorm1d(8),\n",
    "            torch.nn.Tanh(), # torch.nn.ReLU(),\n",
    "            torch.nn.AvgPool1d(3), # torch.nn.MaxPool1d(3),\n",
    "        )\n",
    "\n",
    "        self.fnn1 = torch.nn.Linear(136, 64)\n",
    "        self.fnn2 = torch.nn.Linear(64, 64)\n",
    "        self.fnn3 = torch.nn.Linear(64, 64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.activation(self.fnn1(x))\n",
    "        output = self.activation(self.fnn2(output))\n",
    "        output = self.activation(self.fnn3(output))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0ec3a5",
   "metadata": {},
   "source": [
    "main structure of DeepONet with multiple inputs (two inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8965c2fd",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class DeepONet(nn.Module):\n",
    "\n",
    "    # this deeponet contains 2 branch nets and 1 trunk net\n",
    "    # input_size_branch1: size of input tensor for branch net1\n",
    "    # hidden_layers_branch1: number of hidden layers in branch net1\n",
    "    # hidden_neurons_branch1: number of neurons per hidden layer in branch net1\n",
    "    # input_size_branch2: size of input tensor for branch net2\n",
    "    # hidden_layers_branch2: number of hidden layers in branch net2\n",
    "    # hidden_neurons_branch2: number of neurons per hidden layer in branch net2\n",
    "    # hidden_layers_trunk: number of hidden layers in trunk net\n",
    "    # hidden_neurons_trunk: number of neurons per hidden layer in trunk net\n",
    "    # inner_layer_siz: size of the inner layer, i.e. value of p\n",
    "    # activation: activation function\n",
    "    # size_bias: size of the output bias tensor\n",
    "\n",
    "    def __init__(self, input_size_branch1, hidden_layers_branch1, hidden_neurons_branch1, \\\n",
    "                 input_size_branch2, hidden_layers_branch2, hidden_neurons_branch2, \\\n",
    "                 hidden_layers_trunk, hidden_neurons_trunk, \\\n",
    "                 inner_layer_size, activation, size_bias):\n",
    "\n",
    "        super(DeepONet, self).__init__()\n",
    "        self.branch1 = FNN(input_size_branch1, inner_layer_size, hidden_layers_branch1, \\\n",
    "                           hidden_neurons_branch1, activation)\n",
    "        self.branch2 = CNN() # FNN(input_size_branch2, inner_layer_size, hidden_layers_branch2, \\\n",
    "                           # hidden_neurons_branch2, activation)\n",
    "        self.trunk = FNN(1, inner_layer_size, hidden_layers_trunk, hidden_neurons_trunk, activation)\n",
    "\n",
    "        self.bias = nn.Parameter(torch.Tensor(1, size_bias))\n",
    "\n",
    "    def forward(self, input_tensor_branch1, input_tensor_branch2, input_tensor_trunk):\n",
    "\n",
    "        # input tensor for branch net1 is input_tensor_branch1\n",
    "        # input tensor for branch net2 is input_tensor_branch2\n",
    "        # input tensor for trunk net is input_tensor_trunk\n",
    "\n",
    "        b_tensor = self.branch1(input_tensor_branch1)\n",
    "        s_tensor = self.branch2(input_tensor_branch2)\n",
    "        b = b_tensor * s_tensor\n",
    "\n",
    "        input_tensor_trunk = input_tensor_trunk.view(-1, 1)\n",
    "        t = self.trunk(input_tensor_trunk)\n",
    "\n",
    "        output =  torch.matmul(b, t.T) + self.bias.squeeze()\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319a942d",
   "metadata": {},
   "source": [
    "set up deeponet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fed8165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input of the branch net 1 is the measurement height Z\n",
    "input_size_branch1 = 1\n",
    "hidden_layers_branch1 = 3\n",
    "hidden_neurons_branch1 = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfffbfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input of the branch net 2 is the real and imaginary parts of scattered data\n",
    "input_size_branch2 = N_obs * 2\n",
    "hidden_layers_branch2 = 4\n",
    "hidden_neurons_branch2 = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413b6d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input of the trunk net\n",
    "hidden_layers_trunk = 4\n",
    "hidden_neurons_trunk = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77942d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input layer size, value of p\n",
    "inner_layer_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbb69ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation function\n",
    "activation = nn.Tanh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51e9bda",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('calculation device : ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb1813b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepONet(input_size_branch1, hidden_layers_branch1, hidden_neurons_branch1, \\\n",
    "                 input_size_branch2, hidden_layers_branch2, hidden_neurons_branch2, \\\n",
    "                 hidden_layers_trunk, hidden_neurons_trunk, \\\n",
    "                 inner_layer_size, activation, N_obs).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b892e96a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'start_model_parameters_dirichlet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bbb393",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# count the number of hyperparameters in the neural network\n",
    "def number_parameter_count(network):\n",
    "\n",
    "    num_trainable_para = 0\n",
    "    for param in network.parameters():\n",
    "        if param.requires_grad == True:\n",
    "            num_trainable_para += np.product(param.shape)\n",
    "\n",
    "    return num_trainable_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4879de",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trainable_para = number_parameter_count(model)\n",
    "print(f\"Number of learnable model parameters: {num_trainable_para}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4786bd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the number of training data and testing data\n",
    "size_training_data = 15000\n",
    "size_testing_data = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbd85e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set batch size\n",
    "size_batch = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26520f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose optimizer and learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a49c9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of epochs\n",
    "num_epochs = 15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75544834",
   "metadata": {},
   "outputs": [],
   "source": [
    "time1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd19bab",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# main loop for the deeponet\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    # loof for batches\n",
    "    for i in range(0, size_training_data, size_batch):\n",
    "\n",
    "        # data for the output\n",
    "        hei_data_tensor = normalized_hei_tensors[i:i + size_batch].to(device)\n",
    "\n",
    "        # branch net1 input: measurement height Z\n",
    "        zz_input_tensor = normalized_zz_tensors[i:i + size_batch].to(device)\n",
    "\n",
    "        # branch net2 input: real and imaginary parts of scattered data\n",
    "        sc_real_tensor = normalized_phis_real_tensors[i:i + size_batch].to(device)\n",
    "        sc_imag_tensor = normalized_phis_imag_tensors[i:i + size_batch].to(device)\n",
    "        # sc_input_tensor = torch.cat((sc_real_tensor, sc_imag_tensor), dim=1)\n",
    "        sc_input_tensor = (torch.cat((sc_real_tensor, sc_imag_tensor), dim=1)).unsqueeze(1)\n",
    "\n",
    "        # deeponet output\n",
    "        hei_pred_tensor = model(zz_input_tensor, sc_input_tensor, normalized_x_tensors.to(device))\n",
    "\n",
    "        # loss function\n",
    "        loss = nn.MSELoss()(hei_pred_tensor, hei_data_tensor)\n",
    "\n",
    "        # optimizing step with backward propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}], Loss: {total_loss:.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bb204e",
   "metadata": {},
   "outputs": [],
   "source": [
    "time2 = time.time()\n",
    "time_cost_minutes = (time2 - time1) / 60\n",
    "print(f\"Training time cost: {time_cost_minutes:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2ad243",
   "metadata": {},
   "source": [
    "test results using testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab5a29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntest = 19720"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5168db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original surface height\n",
    "hei_actual_tensor = normalized_hei_tensors[ntest]\n",
    "hei_actual = inverse_normalize_tensor(hei_actual_tensor, hmax, hmin)\n",
    "hei_actual_vec = hei_actual.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5fba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input datas\n",
    "zz_tensor_test = normalized_zz_tensors[ntest].to(device)\n",
    "sc_real_tensor_test = normalized_phis_real_tensors[ntest].to(device)\n",
    "sc_imag_tensor_test = normalized_phis_imag_tensors[ntest].to(device)\n",
    "sc_input_tensor_test = ((torch.cat((sc_real_tensor_test, sc_imag_tensor_test), dim=0)).unsqueeze(0)).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e44806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output data (predicted surface)\n",
    "hei_pred_tensor_test = model(zz_tensor_test, sc_input_tensor_test, normalized_x_tensors.to(device))\n",
    "hei_pred = inverse_normalize_tensor(hei_pred_tensor_test, hmax, hmin)\n",
    "hei_pred_vec = (hei_pred.cpu().detach().numpy()).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73f07e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "line1, = plt.plot(mesh_mid_obs[1:] / lamb, hei_actual_vec / lamb)\n",
    "line2, = plt.plot(mesh_mid_obs[1:] / lamb, hei_pred_vec / lamb)\n",
    "plt.xlabel(r'$x/{\\lambda}$')\n",
    "plt.ylabel(r'$z/{\\lambda}$')\n",
    "leg=plt.legend([line1, line2],\n",
    "        ['actual surface',\n",
    "        'reconstructed surface'], loc = \"best\")\n",
    "plt.savefig(\"without_noise.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3805a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the l2 norm error\n",
    "error_vec = hei_actual_vec - hei_pred_vec\n",
    "print(\"l2 norm error is: \", np.linalg.norm(error_vec) / np.linalg.norm(hei_actual_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088298e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the hyperparameters\n",
    "torch.save(model.state_dict(), 'model_parameters_dirichlet.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49dfef7",
   "metadata": {},
   "source": [
    "test the method with noisy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e983e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntest = 19720"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ded5b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original surface height\n",
    "hei_actual_tensor = normalized_hei_tensors[ntest]\n",
    "hei_actual = inverse_normalize_tensor(hei_actual_tensor, hmax, hmin)\n",
    "hei_actual_vec = hei_actual.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32904639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input datas\n",
    "zz_tensor_test = normalized_zz_tensors[ntest].to(device)\n",
    "sc_real_tensor_test = normalized_phis_real_tensors[ntest].to(device)\n",
    "sc_imag_tensor_test = normalized_phis_imag_tensors[ntest].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79db707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add white noise to the scattered data\n",
    "# noise level eps\n",
    "eps = 0.1\n",
    "# random numbers in [-1,1]\n",
    "random_float = (torch.rand_like(sc_real_tensor_test) - 0.5) * 2\n",
    "sc_real_tensor_noise = sc_real_tensor_test * (1 + eps * random_float)\n",
    "sc_imag_tensor_noise = sc_imag_tensor_test * (1 + eps * random_float)\n",
    "sc_input_tensor_noise = ((torch.cat((sc_real_tensor_noise, sc_imag_tensor_noise), dim=0)).unsqueeze(0)).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622428d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output data (predicted surface)\n",
    "hei_pred_tensor_noise = model(zz_tensor_test, sc_input_tensor_noise, normalized_x_tensors.to(device))\n",
    "hei_pred_noise = inverse_normalize_tensor(hei_pred_tensor_noise, hmax, hmin)\n",
    "hei_pred_vec = (hei_pred_noise.cpu().detach().numpy()).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db963ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "line1, = plt.plot(mesh_mid_obs[1:] / lamb, hei_actual_vec / lamb)\n",
    "line2, = plt.plot(mesh_mid_obs[1:] / lamb, hei_pred_vec / lamb)\n",
    "plt.xlabel(r'$x/{\\lambda}$')\n",
    "plt.ylabel(r'$z/{\\lambda}$')\n",
    "leg=plt.legend([line1, line2],\n",
    "        ['actual surface',\n",
    "        'reconstructed surface'], loc = \"best\")\n",
    "plt.savefig(\"with_noise.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af233c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the l2 norm error\n",
    "error_vec = hei_actual_vec - hei_pred_vec\n",
    "print(\"l2 norm error is: \", np.linalg.norm(error_vec) / np.linalg.norm(hei_actual_vec))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
