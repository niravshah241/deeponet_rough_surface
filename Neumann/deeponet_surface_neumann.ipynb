{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46db26e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"deeponet_surface_neumann.ipynb\n",
    "\n",
    "Automatically generated by Colab.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/github/niravshah241/deeponet_rough_surface/blob/main/Neumann/deeponet_surface_neumann.ipynb\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdc93bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd4489b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set wavenumber and wavelength\n",
    "k = 2.0 * np.pi\n",
    "lamb =  2.0 * np.pi / k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6acff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# domain [la,lb]\n",
    "la = -12.0 * lamb\n",
    "lb = 12.0 * lamb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f04de65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the mesh for calculation\n",
    "N_obs = 240\n",
    "h_obs = (lb - la) / N_obs\n",
    "mesh_obs = np.linspace(la, lb, (N_obs + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0bef8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_mid_obs = np.zeros(N_obs + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7278cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_mid_obs[0] = la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d642b18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for od in range(N_obs):\n",
    "    mesh_mid_obs[od + 1] = (mesh_obs[od] + mesh_obs[od+1])/2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25e37f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform numpy mesh to torch mesh\n",
    "x_mid_obs = torch.tensor(mesh_mid_obs, dtype = torch.float32, requires_grad = True)\n",
    "x_mesh_obs = torch.tensor(mesh_obs, dtype = torch.float32, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520f1794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mesh point input for the trunk network\n",
    "x_tensor = x_mid_obs[1:]\n",
    "x_tensors = x_tensor.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11be3508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# surface height range\n",
    "hmax = 0.2 * lamb\n",
    "hmin = -0.2 * lamb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e75d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data1 = torch.load('data1_neu.pt')\n",
    "data2 = torch.load('data2_neu.pt')\n",
    "data3 = torch.load('data3_neu.pt')\n",
    "data4 = torch.load('data4_neu.pt')\n",
    "data5 = torch.load('data5_neu.pt')\n",
    "data6 = torch.load('data6_neu.pt')\n",
    "data7 = torch.load('data7_neu.pt')\n",
    "data8 = torch.load('data8_neu.pt')\n",
    "data9 = torch.load('data9_neu.pt')\n",
    "data10 = torch.load('data10_neu.pt')\n",
    "data11 = torch.load('data11_neu.pt')\n",
    "data12 = torch.load('data12_neu.pt')\n",
    "data13 = torch.load('data13_neu.pt')\n",
    "data14 = torch.load('data14_neu.pt')\n",
    "data15 = torch.load('data15_neu.pt')\n",
    "data16 = torch.load('data16_neu.pt')\n",
    "data17 = torch.load('data17_neu.pt')\n",
    "data18 = torch.load('data18_neu.pt')\n",
    "data19 = torch.load('data19_neu.pt')\n",
    "data20 = torch.load('data20_neu.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cc93e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data1 + data2 + data3 + data4 + data5 + data6 + data7 + data8 + data9 + data10 \\\n",
    "+ data11 + data12 + data13 +data14 + data15 + data16 + data17 + data18 + data19 + data20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f217a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_data = len(data_train)\n",
    "print('total number of data = ', size_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29edd002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put surface height, scattered data, and measurement height in arrays\n",
    "hei_array = []\n",
    "phis_array = []\n",
    "zz_array = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b402b3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(size_data):\n",
    "    hei_array.append(data_train[i][0])\n",
    "    phis_array.append(data_train[i][1])\n",
    "    zz_array.append(data_train[i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc6ce42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the data in one tensor\n",
    "hei_tensors = torch.stack(hei_array).detach()\n",
    "phis_tensors = torch.stack(phis_array).detach()\n",
    "phis_real_tensors = torch.real(phis_tensors)\n",
    "phis_imag_tensors = torch.imag(phis_tensors)\n",
    "zz_tensors = torch.stack(zz_array).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ea4b24",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# note that the normalzation range is [-0.5,0.5]\n",
    "def normalize_tensor(input_tensor):\n",
    "\n",
    "    min_val = torch.min(input_tensor)\n",
    "    max_val = torch.max(input_tensor)\n",
    "    normalized_tensor = (input_tensor - min_val) / (max_val - min_val) - 0.5\n",
    "\n",
    "    return normalized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaba3102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization of data\n",
    "normalized_hei_tensors = normalize_tensor(hei_tensors)\n",
    "normalized_phis_real_tensors = normalize_tensor(phis_real_tensors)\n",
    "normalized_phis_imag_tensors = normalize_tensor(phis_imag_tensors)\n",
    "normalized_x_tensors = normalize_tensor(x_tensors)\n",
    "normalized_zz_tensors = normalize_tensor(zz_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45af339",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# inverse normalization of data, used for plotting original surface height\n",
    "def inverse_normalize_tensor(normalized_tensor, original_max, original_min):\n",
    "\n",
    "    return (normalized_tensor + 0.5) * (original_max - original_min) + original_min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f974c3",
   "metadata": {},
   "source": [
    "structure for a uniform feed-forward neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a0085f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class FNN(nn.Module):\n",
    "\n",
    "    # input_size: the size of input tensor\n",
    "    # output_size: size of output tensor\n",
    "    # hidden_layers: number of hidden layers\n",
    "    # hidden_neurons: number of hidden neurons per hidden layer\n",
    "    # activation: activation function\n",
    "\n",
    "    def __init__(self, input_size, output_size, hidden_layers, hidden_neurons, activation):\n",
    "\n",
    "        super(FNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.hidden_neurons = hidden_neurons\n",
    "        self.activation = activation\n",
    "\n",
    "        self.input_layer = nn.Linear(input_size, hidden_neurons)\n",
    "        self.hidden_layers_list = nn.ModuleList()\n",
    "        for _ in range(hidden_layers - 1):\n",
    "            self.hidden_layers_list.append(nn.Linear(hidden_neurons, hidden_neurons))\n",
    "        self.output_layer = nn.Linear(hidden_neurons, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.activation(self.input_layer(x))\n",
    "\n",
    "        for hidden_layer in self.hidden_layers_list:\n",
    "            x = self.activation(hidden_layer(x))\n",
    "\n",
    "        x = self.activation(self.output_layer(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c849cda9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.activation = torch.nn.Tanh()\n",
    "        self.conv1d_1 = \\\n",
    "            torch.nn.Conv1d(\n",
    "                in_channels = 1,\n",
    "                out_channels = 4,\n",
    "                kernel_size = 11,\n",
    "                stride = 1,\n",
    "                padding = 2,\n",
    "                )\n",
    "        self.batchnorm1d_1 = \\\n",
    "            torch.nn.BatchNorm1d(4)\n",
    "        self.avgpool1d_1 = \\\n",
    "            torch.nn.AvgPool1d(3)\n",
    "\n",
    "        self.conv1d_2 = \\\n",
    "            torch.nn.Conv1d(\n",
    "                in_channels = 4,\n",
    "                out_channels = 8,\n",
    "                kernel_size = 5,\n",
    "                stride = 1,\n",
    "                padding = 2,\n",
    "                )\n",
    "        self.batchnorm1d_2 = \\\n",
    "            torch.nn.BatchNorm1d(8)\n",
    "        self.avgpool1d_2 = \\\n",
    "            torch.nn.AvgPool1d(3)\n",
    "\n",
    "        self.conv1d_3 = \\\n",
    "            torch.nn.Conv1d(\n",
    "                in_channels = 8,\n",
    "                out_channels = 8,\n",
    "                kernel_size = 5,\n",
    "                stride = 1,\n",
    "                padding = 2,\n",
    "                )\n",
    "        self.batchnorm1d_3 = \\\n",
    "            torch.nn.BatchNorm1d(8)\n",
    "        self.avgpool1d_3 = \\\n",
    "            torch.nn.AvgPool1d(3)\n",
    "\n",
    "        self.fnn1 = torch.nn.Linear(136, 64)\n",
    "        self.fnn2 = torch.nn.Linear(64, 64)\n",
    "        self.fnn3 = torch.nn.Linear(64, 64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1d_1(x)\n",
    "        x = self.batchnorm1d_1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.avgpool1d_1(x)\n",
    "        x = self.conv1d_2(x)\n",
    "        x = self.batchnorm1d_2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.avgpool1d_2(x)\n",
    "        x = self.conv1d_3(x)\n",
    "        x = self.batchnorm1d_3(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.avgpool1d_3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.activation(self.fnn1(x))\n",
    "        x = self.activation(self.fnn2(x))\n",
    "        x = self.activation(self.fnn3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc8ea2c",
   "metadata": {},
   "source": [
    "main structure of DeepONet with multiple inputs (two inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be31513",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class DeepONet(nn.Module):\n",
    "\n",
    "    # this deeponet contains 2 branch nets and 1 trunk net\n",
    "    # input_size_branch1: size of input tensor for branch net1\n",
    "    # hidden_layers_branch1: number of hidden layers in branch net1\n",
    "    # hidden_neurons_branch1: number of neurons per hidden layer in branch net1\n",
    "    # input_size_branch2: size of input tensor for branch net2\n",
    "    # hidden_layers_branch2: number of hidden layers in branch net2\n",
    "    # hidden_neurons_branch2: number of neurons per hidden layer in branch net2\n",
    "    # hidden_layers_trunk: number of hidden layers in trunk net\n",
    "    # hidden_neurons_trunk: number of neurons per hidden layer in trunk net\n",
    "    # inner_layer_siz: size of the inner layer, i.e. value of p\n",
    "    # activation: activation function\n",
    "    # size_bias: size of the output bias tensor\n",
    "\n",
    "    def __init__(self, input_size_branch1, hidden_layers_branch1, hidden_neurons_branch1, \\\n",
    "                 input_size_branch2, hidden_layers_branch2, hidden_neurons_branch2, \\\n",
    "                 hidden_layers_trunk, hidden_neurons_trunk, \\\n",
    "                 inner_layer_size, activation, size_bias):\n",
    "\n",
    "        super(DeepONet, self).__init__()\n",
    "        self.branch1 = FNN(input_size_branch1, inner_layer_size, hidden_layers_branch1, \\\n",
    "                           hidden_neurons_branch1, activation)\n",
    "        self.branch2 = CNN() # FNN(input_size_branch2, inner_layer_size, hidden_layers_branch2, \\\n",
    "                         #   hidden_neurons_branch2, activation)\n",
    "        self.trunk = FNN(1, inner_layer_size, hidden_layers_trunk, hidden_neurons_trunk, activation)\n",
    "\n",
    "        self.bias = nn.Parameter(torch.Tensor(1, size_bias))\n",
    "\n",
    "    def forward(self, input_tensor_branch1, input_tensor_branch2, input_tensor_trunk):\n",
    "\n",
    "        # input tensor for branch net1 is input_tensor_branch1\n",
    "        # input tensor for branch net2 is input_tensor_branch2\n",
    "        # input tensor for trunk net is input_tensor_trunk\n",
    "\n",
    "        b_tensor = self.branch1(input_tensor_branch1)\n",
    "        s_tensor = self.branch2(input_tensor_branch2)\n",
    "        b = b_tensor * s_tensor\n",
    "\n",
    "        input_tensor_trunk = input_tensor_trunk.view(-1, 1)\n",
    "        t = self.trunk(input_tensor_trunk)\n",
    "\n",
    "        output =  torch.matmul(b, t.T) + self.bias.squeeze()\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075cd65b",
   "metadata": {},
   "source": [
    "set up deeponet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78c5555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input of the branch net 1 is the measurement height Z\n",
    "input_size_branch1 = 1\n",
    "hidden_layers_branch1 = 3\n",
    "hidden_neurons_branch1 = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a8223b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input of the branch net 2 is the real and imaginary parts of scattered data\n",
    "input_size_branch2 = N_obs * 2\n",
    "hidden_layers_branch2 = 4\n",
    "hidden_neurons_branch2 = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e7a77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input of the trunk net\n",
    "hidden_layers_trunk = 4\n",
    "hidden_neurons_trunk = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96dd163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input layer size, value of p\n",
    "inner_layer_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bab1242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation function\n",
    "activation = nn.Tanh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d950877",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('calculation device : ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dad9a29",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "model = DeepONet(input_size_branch1, hidden_layers_branch1, hidden_neurons_branch1, \\\n",
    "                 input_size_branch2, hidden_layers_branch2, hidden_neurons_branch2, \\\n",
    "                 hidden_layers_trunk, hidden_neurons_trunk, \\\n",
    "                 inner_layer_size, activation, N_obs).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68658442",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# count the number of hyperparameters in the neural network\n",
    "def number_parameter_count(network):\n",
    "\n",
    "    num_trainable_para = 0\n",
    "    for param in network.parameters():\n",
    "        if param.requires_grad == True:\n",
    "            num_trainable_para += np.product(param.shape)\n",
    "\n",
    "    return num_trainable_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf16d56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trainable_para = number_parameter_count(model)\n",
    "print(f\"Number of learnable model parameters: {num_trainable_para}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4e0b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the number of training data and testing data\n",
    "size_training_data = 15000\n",
    "size_testing_data = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c129be6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set batch size\n",
    "size_batch = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ae2894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose optimizer and learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d10798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of epochs\n",
    "num_epochs = 15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c6bdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "time1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00bf9c3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# main loop for the deeponet\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    # loof for batches\n",
    "    for i in range(0, size_training_data, size_batch):\n",
    "\n",
    "        # data for the output\n",
    "        hei_data_tensor = normalized_hei_tensors[i:i + size_batch].to(device)\n",
    "\n",
    "        # branch net1 input: measurement height Z\n",
    "        zz_input_tensor = normalized_zz_tensors[i:i + size_batch].to(device)\n",
    "\n",
    "        # branch net2 input: real and imaginary parts of scattered data\n",
    "        sc_real_tensor = normalized_phis_real_tensors[i:i + size_batch].to(device)\n",
    "        sc_imag_tensor = normalized_phis_imag_tensors[i:i + size_batch].to(device)\n",
    "        # sc_input_tensor = torch.cat((sc_real_tensor, sc_imag_tensor), dim=1)\n",
    "        sc_input_tensor = (torch.cat((sc_real_tensor, sc_imag_tensor), dim=1)).unsqueeze(1)\n",
    "\n",
    "        # deeponet output\n",
    "        hei_pred_tensor = model(zz_input_tensor, sc_input_tensor, normalized_x_tensors.to(device))\n",
    "\n",
    "        # loss function\n",
    "        loss = nn.MSELoss()(hei_pred_tensor, hei_data_tensor)\n",
    "\n",
    "        # optimizing step with backward propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}], Loss: {total_loss:.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5784b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "time2 = time.time()\n",
    "time_cost_minutes = (time2 - time1) / 60\n",
    "print(f\"Training time cost: {time_cost_minutes:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5553d56f",
   "metadata": {},
   "source": [
    "test results using testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c69c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntest = 19720"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bb3c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original surface height\n",
    "hei_actual_tensor = normalized_hei_tensors[ntest]\n",
    "hei_actual = inverse_normalize_tensor(hei_actual_tensor, hmax, hmin)\n",
    "hei_actual_vec = hei_actual.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153b076d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input datas\n",
    "zz_tensor_test = normalized_zz_tensors[ntest].to(device)\n",
    "sc_real_tensor_test = normalized_phis_real_tensors[ntest].to(device)\n",
    "sc_imag_tensor_test = normalized_phis_imag_tensors[ntest].to(device)\n",
    "# sc_input_tensor_test = torch.cat((sc_real_tensor_test, sc_imag_tensor_test), dim=0)\n",
    "sc_input_tensor_test = ((torch.cat((sc_real_tensor_test, sc_imag_tensor_test), dim=0)).unsqueeze(0)).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e6070f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output data (predicted surface)\n",
    "hei_pred_tensor_test = model(zz_tensor_test, sc_input_tensor_test, normalized_x_tensors.to(device))\n",
    "hei_pred = inverse_normalize_tensor(hei_pred_tensor_test, hmax, hmin)\n",
    "# hei_pred_vec = hei_pred.cpu().detach().numpy()\n",
    "hei_pred_vec = (hei_pred.cpu().detach().numpy()).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaad2ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "line1, = plt.plot(mesh_mid_obs[1:] / lamb, hei_actual_vec / lamb)\n",
    "line2, = plt.plot(mesh_mid_obs[1:] / lamb, hei_pred_vec / lamb)\n",
    "plt.xlabel(r'$x/{\\lambda}$')\n",
    "plt.ylabel(r'$z/{\\lambda}$')\n",
    "leg=plt.legend([line1, line2],\n",
    "        ['actual surface',\n",
    "        'reconstructed surface'], loc = \"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f381991c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the l2 norm error\n",
    "error_vec = hei_actual_vec - hei_pred_vec\n",
    "print(\"l2 norm error is: \", np.linalg.norm(error_vec) / np.linalg.norm(hei_actual_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e89c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the hyperparameters\n",
    "torch.save(model.state_dict(), 'model_parameters_neumann.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0771a23",
   "metadata": {},
   "source": [
    "test the method with noisy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b71e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntest = 19720"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ba886f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original surface height\n",
    "hei_actual_tensor = normalized_hei_tensors[ntest]\n",
    "hei_actual = inverse_normalize_tensor(hei_actual_tensor, hmax, hmin)\n",
    "hei_actual_vec = hei_actual.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefbad4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input datas\n",
    "zz_tensor_test = normalized_zz_tensors[ntest].to(device)\n",
    "sc_real_tensor_test = normalized_phis_real_tensors[ntest].to(device)\n",
    "sc_imag_tensor_test = normalized_phis_imag_tensors[ntest].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858e1144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add white noise to the scattered data\n",
    "# noise level eps\n",
    "eps = 0.1\n",
    "# random numbers in [-1,1]\n",
    "random_float = (torch.rand_like(sc_real_tensor_test) - 0.5) * 2\n",
    "sc_real_tensor_noise = sc_real_tensor_test * (1 + eps * random_float)\n",
    "sc_imag_tensor_noise = sc_imag_tensor_test * (1 + eps * random_float)\n",
    "# sc_input_tensor_noise = torch.cat((sc_real_tensor_noise, sc_imag_tensor_noise), dim=0)\n",
    "sc_input_tensor_noise = ((torch.cat((sc_real_tensor_noise, sc_imag_tensor_noise), dim=0)).unsqueeze(0)).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1baf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output data (predicted surface)\n",
    "hei_pred_tensor_noise = model(zz_tensor_test, sc_input_tensor_noise, normalized_x_tensors.to(device))\n",
    "hei_pred_noise = inverse_normalize_tensor(hei_pred_tensor_noise, hmax, hmin)\n",
    "# hei_pred_vec = hei_pred_noise.cpu().detach().numpy()\n",
    "hei_pred_vec = (hei_pred_noise.cpu().detach().numpy()).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127e39b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "line1, = plt.plot(mesh_mid_obs[1:] / lamb, hei_actual_vec / lamb)\n",
    "line2, = plt.plot(mesh_mid_obs[1:] / lamb, hei_pred_vec / lamb)\n",
    "plt.xlabel(r'$x/{\\lambda}$')\n",
    "plt.ylabel(r'$z/{\\lambda}$')\n",
    "leg=plt.legend([line1, line2],\n",
    "        ['actual surface',\n",
    "        'reconstructed surface'], loc = \"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c09e71",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# calculate the l2 norm error\n",
    "error_vec = hei_actual_vec - hei_pred_vec\n",
    "print(\"l2 norm error is: \", np.linalg.norm(error_vec) / np.linalg.norm(hei_actual_vec))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
